%\VignetteIndexEntry{The LumiR users guide}
%\VignetteDepends{LumiR}
%\VignetteKeywords{Luminex multiplex assay analysis}
%\VignettePackage{LumiR}
\documentclass[11pt]{article}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{underscore}
\usepackage[hmargin=2cm, vmargin=3cm]{geometry}
\SweaveOpts{keep.source=FALSE}

\title{The LumiR User Guide}
\author{Renan Sauteraud\footnote{rsautera@fhcrc.org}}

\begin{document}
\maketitle

\tableofcontents

%\newpage

\section{Introduction}
\subsection{Technology}
Luminex \htmladdnormallink{xMAP}{http://www.luminexcorp.com/TechnologiesScience/xMAPTechnology/} technology is a multiplex assay using flow cytometry to concurrently measure up to 500 analytes in a single reaction volume.

\subsection{LumiR}
\texttt{LumiR} is an R package that provides data structure and functions to read, store and analyze Luminex xMAP experiment.

As with any R package, it should first be loaded in the session
<<loading-package>>=
library(LumiR)
@


\section{Softwares}
Even though Luminex is the company delivering the beads, a wide range of \htmladdnormallink{partners}{http://www.luminexcorp.com/Partners/} offer customizable kits and solutions for acquisition and/or analysis of the data. 
While the technology is identical, the output depends greatly on the software used for the acquisition. In its current version, \texttt{LumiR} can read the data from three different vendors:

\subsection{Luminex}
Luminex's own acquisition software xPONENT produces one csv file per well. These files contain the raw bead level information: bead id, fluorescence measured as well as the fluorescences used to map the bead. \texttt{LumiR} can read data from xPONENT versions 1.x and 3.x.

\subsection{MiraiBio}
MiraiBio also developped a set of tools for the acquisition and analysis of Luminex xMAP platform. The acquisition software `MasterPlex CT' currently in version 1.2 creates one file per well. These binary files with a .lxb extension are based on the format FCS 3.0 and contain the bead level information. Along with these files comes a summary in xml format with a .lxd extension. It contains some information regarding the setup used for the experiment, the matching of the bead id with the analyte name and some basic calculations such as the MFI or the bead count in each well for each analyte.

\subsection{BIO-RAD}
Bio-Plex Manager Software yields files with a proprietary format. However, it allows the user to exports the results in XML files that can be processed by \texttt{LumiR}. The output is a single XML file per experiment gathering all informations available.


\section{Requirements}
In order to read the data into R, the package require the data to be organized in a specific file tree. Additional user-provided information is necessary to run most of the functions in this package.

\subsection{Folders architecture}
Regardless of which software produced the data, the required organization of the folder remains the same. The experiment should be located in a folder (root) with the raw bead level files for each plate in a subfolder named after the plate name or ID. The mapping files should be placed at the root.

\subsection{Analyte mapping file}
In the raw data, the beads are referenced using a unique ID that is specific to a kit and a vendor. In order to use the actual analyte name, the package will look for a file \texttt{`analyte.csv'} that will map each ID to a name. It should contain two columns \textbf{analyte} and \textbf{bid}.
If this file is not submitted by the user, \texttt{LumiR} will still be able to read the data but will display the bead ID instead of the actual name.
Alternately, with MasterPlex CT data, the reading function will look for the .lxd file and attempt to extract this information.

\subsection{Phenotype mapping file}
A \textbf{group_name} and a \textbf{sample_type} (standard, case or control) as well as complementary details like the standards expected \textbf{concentration}, or the case's matching \textbf{control_idx}.

The minimum requirements for the mapping file are the three columns \textbf{plate}, \textbf{well} and \textbf{sample_ID}. If no file is provided, the reading function will try to guess these informations based on the structure of the experiment folder. Additional information regarding the phenotype can be passed in the form of additional columns and should be provided in order to run any analysis such as standard curve fitting.



Additional optional info but if not provided, no analysis can be done.
If nothing is provided, we can still guess
\\\\
An example of each mapping file is provided in the inst folder.
%<<analyte.mapping.file>>=
%path<-system.file("extdata",package="LumiR")
%analyte<-read.csv(file.path(path, "analyte.csv"))
%head(analyte)
%phenotype<-read.csv(file.path(path, "phenotype.csv"))
%head(phenotype,2)
%@
\\\\
The \texttt{setup_templates} function takes the path of an experiment as an argument. It will create extract information regarding the beads used, the matching of filenames wih well ID and plate from the structure of the experiment folder.


\section{Data structure}
\texttt{LumiR} uses two classes to store different level of information.

\subsection{blum}
\texttt{blum} objects store the bead level information: bead id, the two fluorescence levels used for the bead characterization and the measured fluorescence for the analyte.

The reading function \texttt{read.experiment} only argument path takes the pathname of the root folder of an experiment and returns a \texttt{blum} object.
%<<read.experiment>>=
%blum<-read.experiment(path=path)
%@

\subsection{slum}
\texttt{slummarize} is used to create a \texttt{slum}. It calculates the MFI associated with each analyte in each well and uses the given formula to fit the standard curves based on the standard wells.
%<<slummarize>>=
%slum<-slummarize(blum)
%@

\section{Setters}
At some points (either setter on blum/slum and/or ags in slummarize) the user will have to add the potentialy missing phenotype information.

\section{Plate layout}
The function \texttt{plot_layout} makes use of the package \texttt{ggplot2} to display a representation of a plate stored in a \texttt{blum} or \texttt{slum} object.
%<<plotlayout>>=
%plot_layout(slum, plate="plate1", carac="sample_type")
%@


\section{Standard curve fitting}
One of the most common tools for analysis of xMAP data is the Standard Curve. While this package offers new tools for finding significant difference in expression levels between samples, it also implements a standard curve fitting method.

\texttt{geom_sc} is a method that extends \texttt{ggplot2}'s \texttt{geom_line} method. Therefore, it should be added 
%<<geomSc>>=
%p<-ggplot(slum)+geom_point(aes(x=concentration,y=mfi,color=plate),alpha=.5)
%p<-p+scale_x_log10()+scale_y_log10()+theme_bw()
%p+geom_sc(object=bama.mfi,n=10,mapping=aes(x=concentration,y=mfi,color=plate))+facet_wrap(~analyte)
%@
Here we plot the curves for each analyte of the experiment. As seen, multiple plates can be shown at the same time.

\section{SAxCyB}
Saxcyblablabalbal


\end{document}
